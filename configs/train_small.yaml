project_name: chatbot-edu-gpt2
seed: 42

data:
  train_path: data/processed/train.jsonl
  val_path:   data/processed/val.jsonl
  block_size: 512

model:
  base_ckpt: gpt2
  add_special_tokens: ["<|user|>", "<|assistant|>"]
  load_in_8bit: true
  gradient_checkpointing: true

lora:
  enabled: true
  r: 16
  alpha: 32
  dropout: 0.05
  target_modules: ["c_attn","c_proj"]

train:
  epochs: 3
  lr: 5e-5
  wd: 0.01
  train_batch_size: 1
  grad_accum_steps: 16
  eval_steps: 500
  save_steps: 500
  fp16: true

logging:
  report_to: "none"
  output_dir: experiments/runs

infer:
  max_new_tokens: 128
  temperature: 0.7
  top_p: 0.9
